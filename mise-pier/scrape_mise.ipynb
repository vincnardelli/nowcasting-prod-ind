{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraper Ministero dello Sviluppo Economico (MISE) - Consumi Petroliferi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "import requests\n",
    "import bs4\n",
    "import re\n",
    "import os\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "cwd = os.getcwd()\n",
    "pd.set_option('display.max_rows', None) # display all rows df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "![alt text](scraper-image.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get request and parse \n",
    "res = requests.get(\"https://dgsaie.mise.gov.it/consumi_petroliferi.php\")\n",
    "res.raise_for_status()\n",
    "mise = bs4.BeautifulSoup(res.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting link from bs4 parser \n",
    "links = []\n",
    "pre_consuntivi = []\n",
    "definitivi = []\n",
    "\n",
    "# Taking urls as string \n",
    "for link in mise.find_all('a',text=re.compile(\".xls\")):\n",
    "    links.append(link.get('href'))\n",
    "\n",
    "# Choose \n",
    "for link in links:\n",
    "    if \"preconsuntivi\" in link:\n",
    "        pre_consuntivi.append(link)\n",
    "    else:\n",
    "        definitivi.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read online excel without download \n",
    "def excel_to_pandas(URL, local_path):\n",
    "    '''Get an url of an excel file, read its contents\n",
    "         and convert to pandas df '''\n",
    "    resp = requests.get(URL)\n",
    "    with open(local_path, 'wb') as output:\n",
    "        output.write(resp.content)\n",
    "    df = pd.read_excel(local_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:06<00:00,  2.49it/s]\n",
      "100%|██████████| 17/17 [00:04<00:00,  3.54it/s]\n"
     ]
    }
   ],
   "source": [
    "#----------------------\n",
    "# Step 1. Preconsuntivi \n",
    "#----------------------\n",
    "\n",
    "df1 = []\n",
    "\n",
    "for link in tqdm(pre_consuntivi):\n",
    "\n",
    "    # Read url content \n",
    "    df = excel_to_pandas(link,cwd+\"/download.xls\")\n",
    "    \n",
    "    # Take total consumptions and header\n",
    "    rows = [1,2,df[df.iloc[:,0]==\"TOTALE  CONSUMI\"].index.item()]\n",
    "    df = df.iloc[rows]\n",
    "    # Delete bimestrial data\n",
    "    df = df.iloc[:,[2]]\n",
    "    \n",
    "    # Build df \n",
    "    df = pd.DataFrame({\"Mese\": df.iloc[0],\n",
    "                       \"Anno\": df.iloc[1],\n",
    "                       \"Consumi\": df.iloc[2]}).reset_index(drop=True)\n",
    "    \n",
    "    # Clean \n",
    "    df.Mese = df.Mese.str.slice(stop=3).str.lower()\n",
    "    # Append\n",
    "    df1.append(df)\n",
    "    \n",
    "df1 = pd.concat(df1,axis=0)\n",
    "\n",
    "#-----------------\n",
    "# Step 2. Defitivi\n",
    "#-----------------\n",
    "df2 = []\n",
    "\n",
    "for link in tqdm(definitivi):\n",
    "    \n",
    "    # Read url content \n",
    "    df = excel_to_pandas(link,cwd+\"/download2.xls\")\n",
    "    \n",
    "    # Take total consumption \n",
    "    rows = [2, df[df.iloc[:,1]==\"CONSUMI\"].index.item()]\n",
    "    df = df.iloc[rows,2:]\n",
    "    # Find all strings that after a dot contains upper-case letters\n",
    "    mask = df.iloc[0].str.contains('\\.[A-Z]',regex=True,na=False)\n",
    "    # Find all strings that contains only digits \n",
    "    mask2 = df.iloc[1].str.contains('[0-9]', regex=True, na=True)\n",
    "    # Filter with boolean mask \n",
    "    df = df.loc[:,(mask==False) & (mask2==True)]\n",
    "    # Take years of the time-series (set black everything that is not digit)\n",
    "    anno = re.sub('\\D', \"\", link)\n",
    "\n",
    "    # Build df \n",
    "    df = pd.DataFrame({\"Mese\": df.iloc[0],\n",
    "                       \"Anno\": anno,\n",
    "                       \"Consumi\": df.iloc[1]}).reset_index(drop=True)\n",
    "    # Clean \n",
    "    df.Mese = df.Mese.str.replace(\".\",\"\").str.lower()\n",
    "    # Append\n",
    "    df2.append(df)\n",
    "    \n",
    "df2 = pd.concat(df2,axis=0)\n",
    "\n",
    "#---------------------------------\n",
    "# Step 3. Concatenate and save csv\n",
    "#---------------------------------\n",
    "df = df1.append(df2)\n",
    "df.to_csv('consumi-storico.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
